{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ObservationObject.Observation import Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingFramesError(Exception):\n",
    "    \"\"\" Exception raised when no suitable frames are found\n",
    "        \n",
    "        Attributes:\n",
    "            message (string): message that will be displayed on throw        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder existed\n",
      "13:32:22.942451 Creating Observation object...\n",
      "13:32:23.168730 Found 124 fits files\n",
      "13:32:23.168810 Found 46 bias files\n",
      "13:32:23.168851 Found 11 dark files\n",
      "13:32:23.168966 Found 23 flat fields\n",
      "13:32:23.169029 Observation object initialized\n",
      "13:32:23.169073 Saving correction frames...\n",
      "['1x1', '3x3'] ['B', 'V', 'I', 'R']\n",
      "13:32:31.732188 master_bias1x1.fits created\n",
      "13:32:34.734651 master_dark1x1.fits created\n",
      "['B', 'R', 'I']\n",
      "13:32:51.187354 master_flatB1x1.fits created\n",
      "13:32:51.859538 master_flatR1x1.fits created\n",
      "13:32:52.553161 master_flatI1x1.fits created\n",
      "13:32:53.183504 master_bias3x3.fits created\n",
      "13:32:53.578443 master_dark3x3.fits created\n",
      "['I']\n",
      "13:32:54.595667 master_flatI3x3.fits created\n",
      "13:32:54.595840 Correction frames saved!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from astropy.io import fits\n",
    "from shutil import copy2\n",
    "\n",
    "# Define some telescope path constants\n",
    "tele_path = os.path.normpath(\"/net/vega/data/users/observatory/images/\")\n",
    "tele_subdirs = (\"ST-7\", \"STL-6303E\")\n",
    "tele_subsubdirs = (\"g\", \"i\")\n",
    "\n",
    "# Define some user savepaths\n",
    "base_path = os.path.normpath(\"/Users/users/gunnink/PAC/Data/\")\n",
    "raw_dir = \"Raw\"\n",
    "reduced_dir = \"Reduced\"\n",
    "correction_dir = \"Correction\"\n",
    "\n",
    "def load_args():\n",
    "    \"\"\" \n",
    "    Function that specifies the expected arguments\n",
    "    given on the command line by the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sets the description that will be shown with --help\n",
    "    parser = argparse.ArgumentParser(description=\"Program that updates the Blaauw Observatory \\\n",
    "                                                  database by automatically reducing the fits files\")\n",
    "    \n",
    "    # Add required argument for path to observation folder\n",
    "    target = parser.add_mutually_exclusive_group()\n",
    "    target.add_argument(\"-f\", \"--folder\", type=str, help=\"The absolute path to the observation directory\")\n",
    "    target.add_argument(\"-d\", \"--date\", type=str, help=\"The observation date in yy-mm-dd\")\n",
    "    ## Add update functionality --> check for new content\n",
    "    \n",
    "    # Add arguments for the intended action\n",
    "    parser.add_argument(\"-b\", \"--backup\", action=\"store_true\", help=\"Move a copy of the raw data to local folder\")\n",
    "    parser.add_argument(\"-s\", \"--saveraw\", action=\"store_true\", help=\"Save raw correction frames locally\")\n",
    "    parser.add_argument(\"-r\", \"--reduce\", action=\"store_true\", help=\"Reduce all the present light frames\")\n",
    "    parser.add_argument(\"-a\", \"--astrometry\", action=\"store_true\", help=\"Run all light frames through Astrometry\")\n",
    "    #parser.add_argument(\"-p\", \"--preview\", action=\"store_true\", help=\"Create a .png preview per light file\")\n",
    "    #parser.add_argument(\"-m\", \"--metadata\", action=\"store_true\", help=\"Add extra header information (STARALT)\")\n",
    "    \n",
    "    # Add argument for verbosity\n",
    "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Increase the amount of output\")\n",
    "    \n",
    "    # Retrieve the passed arguments and check their validity\n",
    "    args = parser.parse_args()\n",
    "    targets = check_args(parser, args)\n",
    "    \n",
    "    return args, targets\n",
    "\n",
    "def is_valid_date(date_text, date_format):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, date_format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def get_targets_from_folder(folder):\n",
    "    \"\"\" Function that extracts the actual telescope folders from the passed \n",
    "        folder. There exist two options: the given folder is either a specific \n",
    "        dataset, or a parent directory for a specific date. In either case, a \n",
    "        list is returned containing all the valid date subfolders.\n",
    "    \"\"\"\n",
    "    folder = os.path.normpath(folder)\n",
    "    \n",
    "    # In this case, the passed folder is specific\n",
    "    if folder.endswith(tele_subsubdirs):\n",
    "        targets = [folder]\n",
    "        \n",
    "    elif folder.endswith(tele_subdirs):\n",
    "        subdirs = [os.path.join(folder, subdir) for subdir in tele_subsubdirs]\n",
    "        targets = []\n",
    "        for subdir in subdirs:\n",
    "            if len(os.listdir(subdir)) > 0:\n",
    "                targets.append(subdir)\n",
    "        \n",
    "    elif is_valid_date(os.path.basename(os.path.normpath(folder)), \"%y%m%d\"):\n",
    "        subdirs = [os.path.join(folder, subdir) for subdir in tele_subdirs]\n",
    "        targets = []\n",
    "        for subdir in subdirs:\n",
    "            for subsubdir in tele_subsubdirs:\n",
    "                cur_folder = os.path.join(subdir, subsubdir)\n",
    "                if os.path.isdir(cur_folder) and len(os.listdir(cur_folder)) > 0:\n",
    "                    targets.append(cur_folder)\n",
    "                    \n",
    "    else:\n",
    "        print(\"Foldertype not understood\")\n",
    "                \n",
    "    return targets\n",
    "\n",
    "def get_targets_from_date(date_text):\n",
    "    date_stripped = date_text.replace(\"-\", \"\")\n",
    "    folder = os.path.join(tele_path, date_stripped)\n",
    "    \n",
    "    targets = get_targets_from_folder(folder)\n",
    "    return targets\n",
    "\n",
    "def check_args(parser, args):\n",
    "    \"\"\" \n",
    "    Function that checks all the given arguments for their validity. If one\n",
    "    of the required conditions is not met, an error is thrown.\n",
    "    \"\"\"\n",
    "    # Check that a target was specified\n",
    "    if not (args.folder or args.date):\n",
    "        parser.error(f\"Target was not specified: pass a directory path or a date\")\n",
    "    \n",
    "    # If the target is a directory, check that it exists\n",
    "    if args.folder:\n",
    "        if not os.path.isdir(args.folder):\n",
    "            parser.error(f\"{args.folder} is not an existing directory\")\n",
    "        targets = get_targets_from_folder(args.folder)\n",
    "    \n",
    "    # If the target is a date, check that it's a valid date\n",
    "    if args.date:\n",
    "        if not is_valid_date(args.date, \"%y-%m-%d\"):\n",
    "            parser.error(f\"{args.date} is not a valid date. Use the following format: yy-mm-dd\")\n",
    "        targets = get_targets_from_date(args.date)\n",
    "    \n",
    "    # The action was not specified\n",
    "    if not (args.backup or args.saveraw or args.reduce or args.astrometry):\n",
    "        parser.error(\"No action specified. Possible actions include: --backup, --reduce and --astrometry\")\n",
    "        \n",
    "    return targets\n",
    "                \n",
    "def check_obs(obs, args):\n",
    "    if args.verbose:\n",
    "        Print(f\"Found {len(obs.files)} fits files\", args)\n",
    "        Print(f\"Found {len(obs.biasFiles)} bias files\", args)\n",
    "        Print(f\"Found {len(obs.darkFiles)} dark files\", args)\n",
    "        Print(f\"Found {len(obs.flatFiles)} flat fields\", args)\n",
    "        \n",
    "    bias_found = len(obs.biasFiles) > 0\n",
    "    dark_found = len(obs.darkFiles) > 0\n",
    "    flat_found = len(obs.flatFiles) > 0\n",
    "    frame_check = 3\n",
    "\n",
    "    if not bias_found:\n",
    "        warnings.warn(\"No bias files were found\")\n",
    "        frame_check -= 1\n",
    "    if not dark_found:\n",
    "        warnings.warn(\"No dark files were found\")\n",
    "        frame_check -= 1\n",
    "    if not flat_found:\n",
    "        warnings.warn(\"No flat fields were found\")\n",
    "        frame_check -= 1\n",
    "        \n",
    "    if frame_check == 0:\n",
    "        raise MissingFramesError(\"No suitable correction frames found\")\n",
    "    \n",
    "    return\n",
    "\n",
    "def get_binnings(obs, files):\n",
    "    # Returns all binning types for light frames\n",
    "    binnings = []\n",
    "    for file in filters:\n",
    "        cur_binning = obs.get_file_info(file, [\"BINNING\"])[0]\n",
    "        if cur_binning not in binnings:\n",
    "            binnings.append(cur_binning)\n",
    "            \n",
    "    return binnings\n",
    "\n",
    "def get_filters(obs, files):\n",
    "    # Returns all filter types for a given list of files\n",
    "    filters = []\n",
    "    for file in files:\n",
    "        cur_filter = obs.get_file_info(file, [\"FILTER\"])[0]\n",
    "        if cur_filter not in filters:\n",
    "            filters.append(cur_filter)\n",
    "            \n",
    "    return filters\n",
    "\n",
    "def save_fits(content, save_path):\n",
    "    # Add header functionality\n",
    "    hduNew = fits.PrimaryHDU(content)\n",
    "    hduNew.writeto(save_path)\n",
    "\n",
    "def create_backup(obs, working_dir, args):\n",
    "    Print(\"Creating backup...\", args, True)\n",
    "    save_dir = os.path.join(working_dir, raw_dir)\n",
    "    if not os.path.isdir(save_dir): os.mkdir(save_dir)\n",
    "    \n",
    "    for file in obs.files:\n",
    "        copy2(file, save_dir)\n",
    "        break\n",
    "        \n",
    "    Print(\"Backup created!\", args, True)\n",
    "\n",
    "    return\n",
    "\n",
    "def save_correction(obs, working_dir, args):\n",
    "    Print(\"Saving correction frames...\", args, True)\n",
    "    cor_dir = os.path.join(working_dir, correction_dir)\n",
    "    if not os.path.isdir(cor_dir): os.mkdir(cor_dir)\n",
    "        \n",
    "    # Get the unique binnings for this observation\n",
    "    binnings = get_binnings(obs, obs.lightFiles)\n",
    "        \n",
    "    # Loop over every possible binning\n",
    "    for binning in binnings:\n",
    "        # Get the bias files for this binning\n",
    "        bias_created = False\n",
    "        bias_condit = {\"IMAGETYP\": \"Bias Frame\", \"BINNING\": binning}\n",
    "        bias_files = obs.get_files(condit=bias_condit)\n",
    "        # Create and save the master bias\n",
    "        if len(bias_files) > 0:\n",
    "            master_bias = obs.create_master_bias(biasFiles=bias_files)\n",
    "            filename = \"master_bias\" + binning + \".fits\"\n",
    "            save_fits(master_bias, os.path.join(cor_dir, filename))\n",
    "            bias_created = True\n",
    "            Print(f\"{filename} created\", args)\n",
    "        \n",
    "        # Get the dark files for this binning\n",
    "        dark_created = False\n",
    "        dark_condit = {\"IMAGETYP\": \"Dark Frame\", \"BINNING\": binning}\n",
    "        dark_files = obs.get_files(condit=dark_condit)\n",
    "        # Create and save the master dark\n",
    "        if len(dark_files) > 0 and bias_created:\n",
    "            master_dark = obs.create_master_dark(darkFiles=dark_files, masterBias=master_bias)\n",
    "            filename = \"master_dark\" + binning + \".fits\"\n",
    "            save_fits(master_dark, os.path.join(cor_dir, filename))\n",
    "            dark_created = True\n",
    "            Print(f\"{filename} created\", args)\n",
    "        \n",
    "        # Get the flat files for this binning, every filter\n",
    "        flat_condit = {\"IMAGETYP\": \"Flat Field\", \"BINNING\": binning}\n",
    "        flat_files = obs.get_files(condit=bias_condit)\n",
    "        # Create the master flats for the found filters\n",
    "        if len(flat_files) > 0 and bias_created and dark_created:\n",
    "            file_filters = get_filters(obs, flat_files)\n",
    "            master_flats = obs.create_master_flats(flatFiles=flat_files, filterTypes=file_filters,\n",
    "                                                   masterBias=master_bias, masterDark=master_dark)\n",
    "            # Loop over every filter and save the corresponding master flat\n",
    "            for i in range(len(file_filters)):\n",
    "                cur_filter = file_filters[i]\n",
    "                if master_flats.ndim == 2:\n",
    "                    master_flat = master_flats\n",
    "                else:\n",
    "                    master_flat = master_flats[:,:,i]\n",
    "                filename = \"master_flat\" + cur_filter + binning + \".fits\"\n",
    "                save_fits(master_flat, os.path.join(cor_dir, filename))\n",
    "                Print(f\"{filename} created\", args)\n",
    "    \n",
    "    Print(\"Correction frames saved!\", args, True)\n",
    "\n",
    "    return\n",
    "\n",
    "def reduce_imgs(obs, working_dir, args):\n",
    "    Print(\"Reducing images...\", args, True)\n",
    "    \n",
    "    binnings = get_binnings(obs, lightFiles)\n",
    "    filters = get_filters(obs, lightFiles)\n",
    "    \n",
    "    master_bias1x1 = None\n",
    "    master_bias3x3 = None\n",
    "    \n",
    "    for light_file in obs.lightFiles:\n",
    "        binning, fltr = obs.get_file_info(light_file, [\"BINNING\", \"FILTER\"])\n",
    "        # Work in progress...\n",
    "    \n",
    "    return\n",
    "\n",
    "def run_astrometry(obs, working_dir, args):\n",
    "    Print(\"Running astrometry client...\", args, True)\n",
    "    \n",
    "    return\n",
    "        \n",
    "def Print(message, args, forced=False):\n",
    "    now = datetime.datetime.now().time()\n",
    "    if forced:\n",
    "        print(now, message)\n",
    "    elif args.verbose: \n",
    "        print(now, message)\n",
    "        \n",
    "def main():\n",
    "    args, targets = load_args()\n",
    "    \n",
    "    for target in targets:\n",
    "        working_dir_name = os.path.relpath(target, tele_path)\n",
    "        working_dir = os.path.join(base_path, working_dir_name)\n",
    "        if os.path.isdir(working_dir):\n",
    "            # TODO: this means this data probably has been handled already...\n",
    "            # BUT: not sure what exact operations have been carried out\n",
    "            print(\"Folder existed\")\n",
    "        else:\n",
    "            os.makedirs(working_dir)\n",
    "        \n",
    "        Print(\"Creating Observation object...\", args)\n",
    "        obs = Observation(target)\n",
    "        check_obs(obs, args)\n",
    "        Print(\"Observation object initialized\", args, True)\n",
    "    \n",
    "        if args.backup: create_backup(obs, working_dir, args)\n",
    "        if args.saveraw: save_correction(obs, working_dir, args)\n",
    "        if args.reduce: reduce_imgs(obs, working_dir, args)\n",
    "        if args.astrometry: run_astrometry(obs, working_dir, args)\n",
    "    #[print(file) for file in obs.files]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # placeholder\n",
    "    data_dir = \"/net/vega/data/users/observatory/images/200417/STL-6303E/i/\"\n",
    "    date = \"20-04-17\"\n",
    "    \n",
    "#     sys.argv = [\"wrapper.py\", \"-f\", data_dir, \"-bv\"]\n",
    "    sys.argv = [\"wrapper.py\", \"-d\", date , \"-rv\"]\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 - 2019.10",
   "language": "python",
   "name": "python3-2019.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
